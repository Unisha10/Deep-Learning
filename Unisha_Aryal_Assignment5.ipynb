{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement 1"
      ],
      "metadata": {
        "id": "lfa08Dvp4Lwl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ELPnD90LGvG_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Dropout, SimpleRNN, LSTM, GRU\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string, random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"name_gender.csv\")\n",
        "data['name'] = data['name'].apply(lambda x: ''.join(filter(lambda y: y in string.printable, x)))\n",
        "chars = sorted(list(set(''.join(data['name'].values))))\n",
        "\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n"
      ],
      "metadata": {
        "id": "rYTRUKqIGw8N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(cell_type, data_size):\n",
        "    sampled_data = data.sample(frac=data_size, random_state=42)\n",
        "    max_length = max([len(name) for name in sampled_data['name']])\n",
        "    input_data_X = np.zeros((len(sampled_data), max_length, len(chars)), dtype=np.bool)\n",
        "    output_data_Y = np.zeros((len(sampled_data), 2), dtype=np.bool)\n",
        "\n",
        "    for i, name in enumerate(sampled_data['name']):\n",
        "        for j, char in enumerate(name):\n",
        "            input_data_X[i, j, char_to_int[char]] = 1\n",
        "        output_data_Y[i, 0 if sampled_data.iloc[i]['gender'] == 'M' else 1] = 1\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(input_data_X, output_data_Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = Sequential()\n",
        "    if cell_type == 'SimpleRNN':\n",
        "        model.add(SimpleRNN(128, input_shape=(max_length, len(chars))))\n",
        "    elif cell_type == 'LSTM':\n",
        "        model.add(LSTM(128, input_shape=(max_length, len(chars))))\n",
        "    elif cell_type == 'GRU':\n",
        "        model.add(GRU(128, input_shape=(max_length, len(chars))))\n",
        "    else:\n",
        "        print(\"Unexpected cell type\")\n",
        "        return\n",
        "\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, epochs=20, batch_size=128, validation_data=(X_test, y_test), verbose=0)\n",
        "    evaluation_scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    print(\"Cell type:\", cell_type)\n",
        "    print(\"Data size:\", data_size)\n",
        "    print(\"Accuracy: %.2f%%\" % (evaluation_scores[1]*100))\n",
        "\n",
        "    predictions = model.predict(X_test)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    true_classes = np.argmax(y_test, axis=1)\n",
        "    male_indices = np.where(true_classes == 0)[0]\n",
        "    female_indices = np.where(true_classes == 1)[0]\n",
        "    male_accuracy = np.mean(predicted_classes[male_indices] == true_classes[male_indices])\n",
        "    female_accuracy = np.mean(predicted_classes[female_indices] == true_classes[female_indices])\n",
        "    print(\"Male accuracy: %.2f%%\" % (male_accuracy*100))\n",
        "    print(\"Female accuracy: %.2f%%\" % (female_accuracy*100))\n",
        "    print()\n",
        "\n",
        "# Iterating through different cell types and data sizes\n",
        "for cell_type in ['SimpleRNN', 'LSTM', 'GRU']:\n",
        "    for data_size in [0.25, 0.5, 0.75, 1.0]:\n",
        "        train_model(cell_type, data_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM5HpvquGxEY",
        "outputId": "77ad6f30-d6e8-45c4-8208-368994d37c17"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-623f8656bef9>:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  input_data_X = np.zeros((len(sampled_data), max_length, len(chars)), dtype=np.bool)\n",
            "<ipython-input-5-623f8656bef9>:5: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  output_data_Y = np.zeros((len(sampled_data), 2), dtype=np.bool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cell type: SimpleRNN\n",
            "Data size: 0.25\n",
            "Accuracy: 84.45%\n",
            "149/149 [==============================] - 1s 3ms/step\n",
            "Male accuracy: 78.38%\n",
            "Female accuracy: 87.87%\n",
            "\n",
            "Cell type: SimpleRNN\n",
            "Data size: 0.5\n",
            "Accuracy: 87.03%\n",
            "297/297 [==============================] - 1s 4ms/step\n",
            "Male accuracy: 84.78%\n",
            "Female accuracy: 88.35%\n",
            "\n",
            "Cell type: SimpleRNN\n",
            "Data size: 0.75\n",
            "Accuracy: 87.24%\n",
            "446/446 [==============================] - 1s 3ms/step\n",
            "Male accuracy: 85.74%\n",
            "Female accuracy: 88.10%\n",
            "\n",
            "Cell type: SimpleRNN\n",
            "Data size: 1.0\n",
            "Accuracy: 88.69%\n",
            "594/594 [==============================] - 3s 4ms/step\n",
            "Male accuracy: 87.00%\n",
            "Female accuracy: 89.68%\n",
            "\n",
            "Cell type: LSTM\n",
            "Data size: 0.25\n",
            "Accuracy: 86.38%\n",
            "149/149 [==============================] - 1s 3ms/step\n",
            "Male accuracy: 81.30%\n",
            "Female accuracy: 89.25%\n",
            "\n",
            "Cell type: LSTM\n",
            "Data size: 0.5\n",
            "Accuracy: 88.80%\n",
            "297/297 [==============================] - 1s 2ms/step\n",
            "Male accuracy: 86.79%\n",
            "Female accuracy: 89.99%\n",
            "\n",
            "Cell type: LSTM\n",
            "Data size: 0.75\n",
            "Accuracy: 89.57%\n",
            "446/446 [==============================] - 2s 3ms/step\n",
            "Male accuracy: 86.26%\n",
            "Female accuracy: 91.47%\n",
            "\n",
            "Cell type: LSTM\n",
            "Data size: 1.0\n",
            "Accuracy: 90.54%\n",
            "594/594 [==============================] - 2s 2ms/step\n",
            "Male accuracy: 90.05%\n",
            "Female accuracy: 90.83%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 0.25\n",
            "Accuracy: 85.73%\n",
            "149/149 [==============================] - 1s 2ms/step\n",
            "Male accuracy: 78.26%\n",
            "Female accuracy: 89.94%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 0.5\n",
            "Accuracy: 88.87%\n",
            "297/297 [==============================] - 1s 2ms/step\n",
            "Male accuracy: 85.09%\n",
            "Female accuracy: 91.09%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 0.75\n",
            "Accuracy: 89.62%\n",
            "446/446 [==============================] - 1s 2ms/step\n",
            "Male accuracy: 86.53%\n",
            "Female accuracy: 91.39%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 1.0\n",
            "Accuracy: 90.18%\n",
            "594/594 [==============================] - 2s 2ms/step\n",
            "Male accuracy: 90.16%\n",
            "Female accuracy: 90.19%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement 2"
      ],
      "metadata": {
        "id": "y7vklKT54ROU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random, csv\n"
      ],
      "metadata": {
        "id": "X_uM6_c2GxHF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv('name_gender.csv')\n"
      ],
      "metadata": {
        "id": "JRYUTkNdGxKI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter out the rows where gender is unknown or probability is less than 1\n",
        "df = df[(df['gender'] != 'U') & (df['probability'] == 1)]\n"
      ],
      "metadata": {
        "id": "NApDPW8dGxNQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dictionary to store the frequency of each character transition\n",
        "def create_transition_dict(names):\n",
        "    transition_dict = {}\n",
        "    for name in names:\n",
        "        name = name.lower()\n",
        "        for i in range(len(name)-1):\n",
        "            current_char = name[i]\n",
        "            next_char = name[i+1]\n",
        "            if current_char not in transition_dict:\n",
        "                transition_dict[current_char] = {}\n",
        "            if next_char not in transition_dict[current_char]:\n",
        "                transition_dict[current_char][next_char] = 0\n",
        "            transition_dict[current_char][next_char] += 1\n",
        "    return transition_dict\n"
      ],
      "metadata": {
        "id": "ZEsqAza9GxQT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a name based on the Markov Chain model\n",
        "def generate_name(transition_dict, gender):\n",
        "    vowels = 'aeiou'\n",
        "    consonants = 'bcdfghjklmnpqrstvwxyz'\n",
        "    if gender == 'M':\n",
        "        first_letter = random.choice(['a', 'e', 'i', 'o', 'u'] + list(consonants))\n",
        "    else:\n",
        "        first_letter = random.choice(['a', 'e', 'i', 'o', 'u'] + list(vowels))\n",
        "    name = first_letter\n",
        "    current_letter = first_letter\n",
        "    while len(name) < 10:\n",
        "        if current_letter not in transition_dict:\n",
        "            break\n",
        "        next_letter = random.choices(list(transition_dict[current_letter].keys()),\n",
        "                                      list(transition_dict[current_letter].values()))[0]\n",
        "        name += next_letter\n",
        "        current_letter = next_letter\n",
        "    return name.capitalize()"
      ],
      "metadata": {
        "id": "KOA7ldM03mbS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list of male and female names using the Markov Chain model\n",
        "male_names = []\n",
        "female_names = []\n",
        "transition_dict = create_transition_dict(df['name'].values)\n",
        "for index, row in df.iterrows():\n",
        "    if row['gender'] == 'M':\n",
        "        male_names.append(generate_name(transition_dict, 'M'))\n",
        "    else:\n",
        "        female_names.append(generate_name(transition_dict, 'F'))\n"
      ],
      "metadata": {
        "id": "-54wy1lR3mee"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/generated_names.csv', mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the header row\n",
        "    writer.writerow(['gender', 'name'])\n",
        "\n",
        "    # Write the male names\n",
        "    for name in male_names:\n",
        "        writer.writerow(['M', name])\n",
        "\n",
        "    # Write the female names\n",
        "    for name in female_names:\n",
        "        writer.writerow(['F', name])\n",
        "\n"
      ],
      "metadata": {
        "id": "ICMiX7TV3mg5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the generated names\n",
        "print(\"Generated Male Names:\")\n",
        "for name in male_names[:100]:\n",
        "    print(name)\n",
        "print(\"\\nGenerated Female Names:\")\n",
        "for name in female_names[:100]:\n",
        "    print(name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWzML9zf3mjJ",
        "outputId": "d94f5ff1-c11e-4230-90ef-560c284368d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Male Names:\n",
            "Yaitahajay\n",
            "Keaykilaco\n",
            "Waneahacyn\n",
            "Unelylliri\n",
            "Nirahexeja\n",
            "Naronelika\n",
            "Sllaqumbre\n",
            "Wevayeynim\n",
            "Laroyntoll\n",
            "Unquaheyli\n",
            "Rianinntty\n",
            "Teeviabeli\n",
            "Nalyervith\n",
            "Uexoshaian\n",
            "Delifranie\n",
            "Tyavinaree\n",
            "Wnnkickann\n",
            "Oneadonngh\n",
            "Starmeinar\n",
            "Qusaqunaen\n",
            "Shahnnghaq\n",
            "Bhvelinahr\n",
            "Kiaeneetia\n",
            "Eeohladona\n",
            "Peshiarlee\n",
            "Junanddiel\n",
            "Yaravunsho\n",
            "Tetrietaro\n",
            "Genntynank\n",
            "Hueziamiau\n",
            "Wdermarely\n",
            "Fomuliaici\n",
            "Benialetye\n",
            "Qualanielo\n",
            "Oanarndenw\n",
            "Nnoriaijar\n",
            "Llennntiro\n",
            "Uelasisier\n",
            "Naveaysere\n",
            "Jainadatax\n",
            "Tuamandiya\n",
            "Leetanenca\n",
            "Ohzaubrdin\n",
            "Telannenda\n",
            "Alenjeemee\n",
            "Hemetieyta\n",
            "Jahalikhil\n",
            "Walanazaya\n",
            "Guettamand\n",
            "Ghaheayara\n",
            "Xiasawrlai\n",
            "Kedanakopi\n",
            "Ronelaizia\n",
            "Xtanluishe\n",
            "Zjishosika\n",
            "Lenjerlaiy\n",
            "Xlyakratai\n",
            "Geingenywe\n",
            "Zahnamarda\n",
            "Kmadureise\n",
            "Hazarinyrj\n",
            "Ashikahiei\n",
            "Hnorahahah\n",
            "Jauldidatt\n",
            "Xareaymari\n",
            "Jananarele\n",
            "Tishahaikl\n",
            "Eeningupah\n",
            "Traleelist\n",
            "Jondanyrab\n",
            "Inichamcil\n",
            "Yasarealen\n",
            "Jenisallel\n",
            "Kynimingil\n",
            "Useckirenn\n",
            "Viahyarixt\n",
            "Danimzarde\n",
            "Hoejekiyah\n",
            "Ueerzanorr\n",
            "Salynstyon\n",
            "Gelmayeyrt\n",
            "Voneniyoll\n",
            "Hekekonttt\n",
            "Diaredyabr\n",
            "Shalleinth\n",
            "Kauzhoriab\n",
            "Onnnizamag\n",
            "Fonemaynie\n",
            "Phemofenyd\n",
            "Chnaniksen\n",
            "Llinindena\n",
            "Chahasanan\n",
            "Aissalelbr\n",
            "Honelavile\n",
            "Tanyaestas\n",
            "Deshitarry\n",
            "Payajennay\n",
            "Rulekeiele\n",
            "Halayossin\n",
            "Llynayarap\n",
            "\n",
            "Generated Female Names:\n",
            "Orchantiai\n",
            "Elasharaye\n",
            "Omaevinyau\n",
            "Etidesharl\n",
            "Urialijayt\n",
            "Uchearayio\n",
            "Ushaawnnta\n",
            "Imayalasic\n",
            "Olevinykea\n",
            "Uvshilaral\n",
            "Orilonacer\n",
            "Ahenayndah\n",
            "Oemashontl\n",
            "Onnelelyli\n",
            "Ahaldearux\n",
            "Aibephexym\n",
            "Einqushica\n",
            "Adishariki\n",
            "Ilicahieya\n",
            "Ifenteenae\n",
            "Ohianeleiq\n",
            "Ondanerand\n",
            "Uarviyasin\n",
            "Ouliacenal\n",
            "Iahrasarit\n",
            "Omminaneje\n",
            "Uryarlijik\n",
            "Ihrrnnicar\n",
            "Iaiabyacam\n",
            "Ornaulyhau\n",
            "Akudominac\n",
            "Ashaderiyn\n",
            "Ieelluauan\n",
            "Arqulichma\n",
            "Erisaleite\n",
            "Orereriyic\n",
            "Oneelyiack\n",
            "Eshlancrde\n",
            "Aliashysef\n",
            "Ialerereth\n",
            "Erilesyery\n",
            "Amavecelyn\n",
            "Aehalishel\n",
            "Esaaminren\n",
            "Oasheerecq\n",
            "Alarieline\n",
            "Enomidodre\n",
            "Erluahadik\n",
            "Izexoneahe\n",
            "Icilssesmi\n",
            "Anshiacela\n",
            "Ansharinua\n",
            "Ichanthela\n",
            "Eharaymane\n",
            "Ilanellyoj\n",
            "Udierylees\n",
            "Iopelanzee\n",
            "Alavermont\n",
            "Udardajoxs\n",
            "Enaetoninn\n",
            "Arrenialab\n",
            "Ondiviaryn\n",
            "Ameailaish\n",
            "Aieloonnat\n",
            "Onaajender\n",
            "Onnannernd\n",
            "Amaxmetobr\n",
            "Inndyahiev\n",
            "Eeckisusck\n",
            "Efrooichet\n",
            "Ahamarouda\n",
            "Ennndarann\n",
            "Orelynnifr\n",
            "Onatorarde\n",
            "Ontharzhar\n",
            "Imeririall\n",
            "Elyavoreri\n",
            "Avelearmar\n",
            "Ityakqusac\n",
            "Emikishawn\n",
            "Abreshshad\n",
            "Iquiyjelen\n",
            "Orietrurea\n",
            "Iliachavia\n",
            "Omalastzyl\n",
            "Ishorgeros\n",
            "Ussalerhik\n",
            "Eriforeeit\n",
            "Aqukashnel\n",
            "Ueenaiylee\n",
            "Iserivilto\n",
            "Edamelbriz\n",
            "Oshonneylo\n",
            "Ilinakayap\n",
            "Ushaumiysy\n",
            "Eeauieylli\n",
            "Ueejaxanya\n",
            "Esarilosir\n",
            "Elyadenamb\n",
            "Ienidennia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/generated_names.csv\")\n",
        "data['name'] = data['name'].apply(lambda x: ''.join(filter(lambda y: y in string.printable, x)))\n",
        "chars = sorted(list(set(''.join(data['name'].values))))\n",
        "\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "male_count = 0\n",
        "for name in male_names:\n",
        "    if train_model(\"GRU\", 1.0) == \"M\":\n",
        "        male_count += 1\n",
        "        male_accuracy = male_count / len(male_names)\n",
        "        exit\n",
        "\n",
        "female_count = 0\n",
        "for name in female_names:\n",
        "    if train_model(\"GRU\", 1.0) == \"F\":\n",
        "        female_count += 1\n",
        "        female_accuracy = female_count / len(female_names)\n",
        "        exit\n",
        "\n",
        "print(\"Accuracy on generated male names: \", male_accuracy)\n",
        "print(\"Accuracy on generated female names: \", female_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "dWaLT3y-8CCV",
        "outputId": "69d3ec59-7680-4220-d7d7-cfe8fcf2643d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-623f8656bef9>:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  input_data_X = np.zeros((len(sampled_data), max_length, len(chars)), dtype=np.bool)\n",
            "<ipython-input-5-623f8656bef9>:5: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  output_data_Y = np.zeros((len(sampled_data), 2), dtype=np.bool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cell type: GRU\n",
            "Data size: 1.0\n",
            "Accuracy: 93.52%\n",
            "530/530 [==============================] - 2s 3ms/step\n",
            "Male accuracy: 81.13%\n",
            "Female accuracy: 100.00%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 1.0\n",
            "Accuracy: 93.52%\n",
            "530/530 [==============================] - 1s 2ms/step\n",
            "Male accuracy: 81.13%\n",
            "Female accuracy: 100.00%\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-e86faee2d900>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmale_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmale_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GRU\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"M\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mmale_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmale_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmale_count\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmale_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-623f8656bef9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(cell_type, data_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mevaluation_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Probelem Statement 2a"
      ],
      "metadata": {
        "id": "k2233dSv4We7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.utils import to_categorical\n",
        "import nltk"
      ],
      "metadata": {
        "id": "uvr0OB1h3mol"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the names dataset from the NLTK library\n",
        "nltk.download('names')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7vFF11WGxTg",
        "outputId": "16816445-5679-4e71-84b0-72ec09e6f38f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the names dataset and filter names starting with 'a', 'm', or 'z'\n",
        "names = nltk.corpus.names.words('/content/name_gender.csv')\n",
        "names = [name.lower() for name in names if name[0].lower() in ['a', 'm', 'z']]\n"
      ],
      "metadata": {
        "id": "wotUoa2C4vxg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a set of unique characters in the names and create character-to-integer mappings\n",
        "chars = sorted(list(set(' '.join(names))))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n"
      ],
      "metadata": {
        "id": "GZBzMwNS4v0x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the sequence length for training data\n",
        "seq_length = 10\n",
        "dataX = []\n",
        "dataY = []\n",
        "\n",
        "# Create input sequences and corresponding output for training\n",
        "for name in names:\n",
        "    for i in range(len(name)-seq_length):\n",
        "        seq_in = name[i:i+seq_length]\n",
        "        seq_out = name[i+seq_length]\n",
        "        dataX.append([char_to_int[char] for char in seq_in])\n",
        "        dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "\n",
        "# Reshape the input sequences for the LSTM model\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "X = X / float(len(chars))\n",
        "y = to_categorical(dataY)\n",
        "\n",
        "# Create an LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=20, batch_size=128)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq6KP2Q44v3h",
        "outputId": "a84521b8-de4a-4d35-ca69-837288af8929"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "355/355 [==============================] - 11s 8ms/step - loss: 2.1032\n",
            "Epoch 2/20\n",
            "355/355 [==============================] - 3s 8ms/step - loss: 1.6333\n",
            "Epoch 3/20\n",
            "355/355 [==============================] - 2s 7ms/step - loss: 1.5195\n",
            "Epoch 4/20\n",
            "355/355 [==============================] - 2s 5ms/step - loss: 1.4984\n",
            "Epoch 5/20\n",
            "355/355 [==============================] - 2s 6ms/step - loss: 1.4865\n",
            "Epoch 6/20\n",
            "355/355 [==============================] - 2s 4ms/step - loss: 1.4796\n",
            "Epoch 7/20\n",
            "355/355 [==============================] - 2s 5ms/step - loss: 1.4749\n",
            "Epoch 8/20\n",
            "355/355 [==============================] - 2s 5ms/step - loss: 1.4707\n",
            "Epoch 9/20\n",
            "355/355 [==============================] - 2s 5ms/step - loss: 1.4667\n",
            "Epoch 10/20\n",
            "355/355 [==============================] - 2s 6ms/step - loss: 1.4644\n",
            "Epoch 11/20\n",
            "355/355 [==============================] - 2s 6ms/step - loss: 1.4625\n",
            "Epoch 12/20\n",
            "355/355 [==============================] - 2s 5ms/step - loss: 1.4604\n",
            "Epoch 13/20\n",
            "355/355 [==============================] - 2s 4ms/step - loss: 1.4583\n",
            "Epoch 14/20\n",
            "355/355 [==============================] - 2s 4ms/step - loss: 1.4563\n",
            "Epoch 15/20\n",
            "355/355 [==============================] - 2s 4ms/step - loss: 1.4554\n",
            "Epoch 16/20\n",
            "355/355 [==============================] - 2s 4ms/step - loss: 1.4536\n",
            "Epoch 17/20\n",
            "355/355 [==============================] - 2s 5ms/step - loss: 1.4527\n",
            "Epoch 18/20\n",
            "355/355 [==============================] - 2s 5ms/step - loss: 1.4503\n",
            "Epoch 19/20\n",
            "355/355 [==============================] - 2s 6ms/step - loss: 1.4492\n",
            "Epoch 20/20\n",
            "355/355 [==============================] - 2s 5ms/step - loss: 1.4476\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78c758d7e260>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and print 50 names using the trained model\n",
        "for i in range(50):\n",
        "    start = np.random.randint(0, len(dataX)-1)\n",
        "    pattern = dataX[start]\n",
        "    name = [int_to_char[value] for value in pattern]\n",
        "\n",
        "    for j in range(20):\n",
        "        x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "        x = x / float(len(chars))\n",
        "        prediction = model.predict(x, verbose=0)\n",
        "        index = np.argmax(prediction)\n",
        "        result = int_to_char[index]\n",
        "        name.append(result)\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "        if result == '.':\n",
        "            break\n",
        "\n",
        "    print(''.join(name).capitalize())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vb4po4S4v6S",
        "outputId": "b1689be0-1a6d-43b9-ed18-9720fbc6fe42"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nnalise,f,1.\n",
            "Bbigayl,f,1.\n",
            "M,0.80334666666666666666666666\n",
            "Ell,f,0.7766666666666666666666\n",
            "Marcelene,f,1.\n",
            "Anna,f,0.999666666666666666666\n",
            ".93150684966666666666666666666\n",
            "Ne,f,0.99966666666666666666666\n",
            ".83333333355666666666666666666\n",
            "Rycaroline,f,1.\n",
            "984413453666666666666666666666\n",
            "Cdaniel,m,1.\n",
            "Addison,f,1.\n",
            "368290668866666666666666666666\n",
            "615384615366666666666666666666\n",
            "053876786166666666666666666666\n",
            "F,0.90156566666666666666666666\n",
            "Maylon,m,0.\n",
            "Allie,f,0.99666666666666666666\n",
            "Maryella,f,1.\n",
            "N,m,0.965566666666666666666666\n",
            "M,0.99978666666666666666666666\n",
            ",0.945375066666666666666666666\n",
            "821782178266666666666666666666\n",
            ",m,0.8577466666666666666666666\n",
            "Hlan,f,0.996666666666666666666\n",
            "054421768766666666666666666666\n",
            "Ckennah,f,1.\n",
            "Martavion,m,1.\n",
            "999593727166666666666666666666\n",
            "539682539666666666666666666666\n",
            "Arquevious,m,1.\n",
            "Aryfrances,m,1.\n",
            ",m,0.5998666666666666666666666\n",
            "596379921666666666666666666666\n",
            "Dreyanna,f,1.\n",
            "064516129056666666666666666666\n",
            "Agapita,f,1.\n",
            "A,f,0.999666666666666666666666\n",
            "Aleceia,f,1.\n",
            "F,0.99854966666666666666666666\n",
            "Andraya,f,1.\n",
            "Airabella,f,1.\n",
            ".96793002946666666666666666666\n",
            "420118343156666666666666666666\n",
            "Arshana,f,1.\n",
            "390243902466666666666666666666\n",
            "Mazaria,f,1.\n",
            "Ameliana,f,1.\n",
            "Zyaire,m,0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "split_index = int(len(dataX) * 0.9)\n",
        "trainX, testX = dataX[:split_index], dataX[split_index:]\n",
        "trainY, testY = dataY[:split_index], dataY[split_index:]\n"
      ],
      "metadata": {
        "id": "a4waa0C54v9G"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Assuming seq_length is the desired fixed length\n",
        "seq_length = 10\n",
        "\n",
        "# Pad or truncate sequences to the fixed length\n",
        "testX = pad_sequences(testX, maxlen=seq_length, padding='post', truncating='post')\n",
        "\n",
        "# Reshape the testing data and convert output to categorical\n",
        "testX = np.reshape(testX, (len(testX), seq_length, 1))\n",
        "testX = testX / float(len(chars))\n",
        "testY = to_categorical(testY)\n",
        "# Reshape the testing data and convert output to categorical\n",
        "testX = np.reshape(testX, (len(testX), seq_length, 1))\n",
        "testX = testX / float(len(chars))\n",
        "testY = to_categorical(testY)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sdr2Bc_D4v_e"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perplexities = []\n",
        "\n",
        "# Generate 50 names and calculate perplexity for each\n",
        "for i in range(50):\n",
        "    start = np.random.randint(0, len(testX)-1)\n",
        "    pattern = testX[start]\n",
        "    name = [int_to_char[value] for value in pattern.flatten()]\n",
        "\n",
        "    perplexity = 1.0\n",
        "    for j in range(20):\n",
        "        x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "        x = x / float(len(chars))\n",
        "        prediction = model.predict(x, verbose=0)\n",
        "        index = np.argmax(prediction)\n",
        "        result = int_to_char[index]\n",
        "        name.append(result)\n",
        "        pattern = np.append(pattern, index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "        if result == '.':\n",
        "            break\n",
        "        perplexity *= prediction[0][index]\n",
        "\n",
        "    perplexity = pow(perplexity, -1/len(name))\n",
        "    perplexities.append(perplexity)\n",
        "    print(''.join(name).capitalize(), 'Perplexity:', perplexity)\n",
        "\n",
        "# Calculate and print the average perplexity\n",
        "avg_perplexity = sum(perplexities) / len(perplexities)\n",
        "print('Average Perplexity:', avg_perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuJvmcGQ4wCS",
        "outputId": "44b194f5-2fac-4a27-9fb1-825a320d2b63"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "          45555556666666666666 Perplexity: 3.395727594459409\n",
            "Average Perplexity: 3.3957275944594096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A2LqtK-94wFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EnYcfQBa4wJ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}